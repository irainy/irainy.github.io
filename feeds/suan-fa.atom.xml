<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>rainy</title><link href="http://defsniky.com/" rel="alternate"></link><link href="http://defsniky.com/feeds/suan-fa.atom.xml" rel="self"></link><id>http://defsniky.com/</id><updated>2013-12-09T00:00:00+08:00</updated><entry><title>图像处理的第一步：选择并抽取正确的特征</title><link href="http://defsniky.com/posts/2013-12-09-choose-and-extract-the-right-features.html" rel="alternate"></link><updated>2013-12-09T00:00:00+08:00</updated><author><name>rainy</name></author><id>tag:defsniky.com,2013-12-09:posts/2013-12-09-choose-and-extract-the-right-features.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;特征提取&lt;/strong&gt;是计算机视觉和图像处理中的一个概念...特征提取的结果是把图像上的点分为不同的子集，这些子集往往属于孤立的点、连续的曲线或者连续的区域(&lt;a href="http://zh.wikipedia.org/wiki/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96"&gt;Wiki&lt;/a&gt;)。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;基本上来说，图像处理任务首先都是要选取与任务相关的特征（如人脸识别中人脸的特征、边缘检测中边缘的特征等），然后将这些特征从复杂多变的背景信息中分离出来，再进行更进一步的处理。因而选择一个好的特征至关重要，后续的精细加工都是基于前面定位、过滤、抽取出来的较为单纯的特征信息，以图像中文字定位为例来说，常用的方法大致可以分为两种类型：基于连通域的方法和基于纹理的方法（脚注没修好，这里就不引用参考文献了），实际上就是针对于图像中的文字通常具有“在相对连续区域内颜色相同”以及“笔画之间夹杂细小缝隙的纹理或空间频率特征”。&lt;/p&gt;
&lt;p&gt;常用的图像特征有颜色特征、纹理特征、形状特征、空间关系特征等(&lt;a href="http://blog.sina.com.cn/s/blog_4e6680090100d2s9.html"&gt;Ref-1&lt;/a&gt;)。但是如何从这些特征中去选取最合适当前任务的特征呢？我们知道有一种“机器”在图像处理任务中做得非常出色，那就是人的视觉系统，David Marr 的经典著作 《&lt;em&gt;&lt;a href="http://book.douban.com/subject/5273663/"&gt;Vision&lt;/a&gt;&lt;/em&gt;》中也有提到，在最初人们想要用计算机去处理图像信息时并没有多少人想到这会有多难，毕竟对我们人类来说这些都是非常直觉、简单的加工过程，甚至在我们都还没有意识到的情况下视觉、认知系统已经完成了对图像的深度加工。而当人们真正着手去做的时候才发现，即使是最简单的 feature detector 要实现也是困难重重，在毫无头绪与经验的情况下所能采取的一种方法就是厚着脸皮不停尝试，正如 David Marr 所描述的 &lt;code&gt;unashamedly empirical approach :P&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;还是以文字定位为例，基于连通域的方法关键在于让文字区域的颜色或灰度值能够与不同图像的背景分离开来，因此采用什么样的颜色空间、取多大的阈值分离背景、通过怎样的形态学变化填充、联通文字所在的区域就成了算法需要调整的关键参数（这只是我基于多次尝试、对比得出的结论，因而未必最优，也没有理论的基础）。首先是颜色空间的选择，在尝试了&lt;a href="http://zh.wikipedia.org/wiki/HSV%E8%89%B2%E5%BD%A9%E5%B1%9E%E6%80%A7%E6%A8%A1%E5%BC%8F"&gt;HSV&lt;/a&gt;、&lt;a href="http://zh.wikipedia.org/wiki/CMYK"&gt;CMYK&lt;/a&gt;等之后，最后转向了&lt;a href="http://zh.wikipedia.org/wiki/Lab%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%97%B4"&gt;Lab色彩空间&lt;/a&gt;(&lt;a href="http://www.cnblogs.com/skyseraph/archive/2011/08/11/2135291.html"&gt;Ref-2&lt;/a&gt;):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class="sd"&gt;OpenCV-python codes&lt;/span&gt;
&lt;span class="sd"&gt;&amp;#39;&amp;#39;&amp;#39;&lt;/span&gt;

&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;cv2&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;numpy&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;np&lt;/span&gt;

&lt;span class="n"&gt;org&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;imread&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;src&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cvtColor&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;COLOR_BGR2LAB&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;org&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;imshow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;src&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;src&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;waitKey&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;destroyAllWindows&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt="处理结果" src="/theme/images/blog/sicp.png" title="处理结果" /&gt;&lt;/p&gt;
&lt;p&gt;Wiki 中提到：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;不像RGB和CMYK色彩空间，Lab颜色被设计来接近人类视觉。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;不知道这是不是巧合，但可以肯定的是即便如此 Lab颜色也不会适合所有的处理任务。接下来通过阈值化、形态学变化等进一步分离特征：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;random&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;randint&lt;/span&gt;

&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;threshold&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;157&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;THRESH_BINARY&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;morphologyEx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MORPH_OPEN&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;getStructuringElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MORPH_RECT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
&lt;span class="n"&gt;res&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;morphologyEx&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;MORPH_CLOSE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;getStructuringElement&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;MORPH_RECT&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="n"&gt;fc&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;res&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;copy&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;contours&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;hierarchy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;findContours&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fc&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;contours&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;cnt&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;c&lt;/span&gt;
    &lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;boundingRect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cnt&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;50&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;h&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;continue&lt;/span&gt;
    &lt;span class="n"&gt;rectangle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;org&lt;/span&gt;&lt;span class="p"&gt;,(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;),(&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;),(&lt;/span&gt;&lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;randint&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="mi"&gt;255&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;结果如下：&lt;/p&gt;
&lt;p&gt;&lt;img alt="最终结果" src="/theme/images/blog/sicp_res.png" title="最终结果" /&gt;&lt;/p&gt;
&lt;p&gt;后面的阈值化等操作的分离效果很大程度上来说并不取决于参数的选取，尤其是考虑到不同的图像中文字颜色、尺寸及其与背景噪音的对比，能否将特征分离出来更多还是取决于颜色空间的选取。&lt;/p&gt;</summary><category term="OpenCV"></category><category term="Python"></category><category term="Vision"></category></entry><entry><title>BP神经网络实践 - 代码识别器</title><link href="http://defsniky.com/posts/2013-06-23-Practice-for-BP-network.html" rel="alternate"></link><updated>2013-06-23T00:00:00+08:00</updated><author><name>rainy</name></author><id>tag:defsniky.com,2013-06-23:posts/2013-06-23-Practice-for-BP-network.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.ibm.com/developerworks/cn/linux/other/l-neural/index.html"&gt;神经网络介绍&lt;/a&gt;一文介绍了用神经网络算法进行代码识别的方法，即:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;假设给出 500 个字符的代码段，您知道它们是 C、C++、Java 或者 Python。现在构造一个程序，来识别编写这段代码的语言。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;所用代码来自：&lt;a href="http://gnosis.cx/download/neural_net_1.zip"&gt;代码识别&lt;/a&gt;，主要实现一个神经网络&lt;a href="https://github.com/sniky/A-N-N/blob/master/bp_net_code_recognizer/bpnn.py"&gt;NN&lt;/a&gt;，于是从 github 上分别抓取了C、Java、Python的代码，来做一下测试，其中：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;C语言：1759个文件，Java：3333个文件，Python：1909个文件。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先统计分析代码中20个特殊字符出现的频率，作为输入节点(&lt;a href="https://github.com/sniky/A-N-N/blob/master/bp_net_code_recognizer/statistic.py"&gt;统计代码见这里&lt;/a&gt;)，并重载了test方法，输出测试准确率：&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;test&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;testPat&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;cor&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;testPat&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;mask&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;flag&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;CORR&amp;quot;&lt;/span&gt;
                &lt;span class="n"&gt;cor&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;flag&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;INCORR&amp;quot;&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Output -&amp;gt; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;flag&lt;/span&gt;
        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Test result: &lt;/span&gt;&lt;span class="si"&gt;%.2f%%&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cor&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;testPat&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;测试结果&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过调整&lt;code&gt;TRAIN_SIZE&lt;/code&gt;、&lt;code&gt;TEST_SIZE&lt;/code&gt;从&lt;a href="https://github.com/sniky/A-N-N/tree/master/bp_net_code_recognizer/dataSet"&gt;dataSet&lt;/a&gt;下的统计结果中抽取一定数量的数据作为训练和测试：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;TRAIN_SIZE = 20, TEST_SIZE = 600&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;迭代次数为8000，最终训练差误收敛至&lt;span style="color:red"&gt;0.046145&lt;/span&gt;，测试准确率为&lt;span style="color:green"&gt;88.50%&lt;/span&gt;；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;TRAIN_SIZE = 10, TEST_SIZE = 600&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;最终训练差误收敛至&lt;span style="color:red"&gt;0.016267&lt;/span&gt;，测试准确率为&lt;span style="color:green"&gt;85.83%&lt;/span&gt;；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;TRAIN_SIZE = 50, TEST_SIZE = 600&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;最终训练差误收敛至&lt;span style="color:red"&gt;2.203505&lt;/span&gt;，测试准确率为&lt;span style="color:green"&gt;65.44%&lt;/span&gt;；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;TRAIN_SIZE = 10, TEST_SIZE = 1200&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;最终训练差误收敛至&lt;span style="color:red"&gt;0.015848&lt;/span&gt;，测试准确率为&lt;span style="color:green"&gt;85.97%&lt;/span&gt;；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;总结&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;从测试结果来看，训练数量越小，误差可以收敛到越小；增加测试数量，也可以提高最终准确率。或者说所选取的特征能否作为甄别、分类的有效指标，也需要做预先的判别。&lt;/p&gt;</summary><category term="ANN"></category><category term="BP"></category><category term="Python"></category></entry></feed>