<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>rainy</title><link href="http://defsniky.com/" rel="alternate"></link><link href="http://defsniky.com/feeds/ren-zhi.atom.xml" rel="self"></link><id>http://defsniky.com/</id><updated>2014-05-14T00:00:00+08:00</updated><entry><title>Why SVM</title><link href="http://defsniky.com/posts/2014-05-14-Why-using-SVM-in-scene-categorization-always.html" rel="alternate"></link><updated>2014-05-14T00:00:00+08:00</updated><author><name>rainy</name></author><id>tag:defsniky.com,2014-05-14:posts/2014-05-14-Why-using-SVM-in-scene-categorization-always.html</id><summary type="html">&lt;p&gt;自然场景识别或分类无论是在机器视觉(Computer Vision)领域还是认知心理学的研究范畴中都离不开机器学习算法的辅助，而机器学习算法中至关重要的两个步骤分别是提取(选取)特征与学习算法。最近读到一系列关于场景识别的心理学研究，通常会用SVM算法与人类观察者实验结果进行对比，并据以论证所假设的某些特征在场景识别中的有效性，且先不说这一论证方法逻辑的可靠性，为什么多数研究会采用SVM算法呢？&lt;/p&gt;
&lt;p&gt;首先看一下SVM(Support Vector Machine)算法，SVM是一种扩展的线性模型，它通过非线性映射的转换，将特征空间转换为一个维度更高的空间，从而实现非线性分类边界的划分，下面这张图能够很好第说明这一特点，原本二维空间里面线性不可分的两类，投射到三维空间后就变得很好区分了：&lt;/p&gt;
&lt;p&gt;&lt;img alt="svm" src="/theme/images/blog/svm.gif" title="“SVM”" /&gt;&lt;/p&gt;
&lt;p&gt;除此之外它还具有另外一些有点，例如SVM是取能够区分两个类别中“相距”最小的实例之间的决策平面，因而能够很好地规避过度拟合的现象(Overfitting，具体可参考&lt;a href="http://www.cnblogs.com/LeftNotEasy/archive/2011/05/02/basic-of-svm.html"&gt;机器学习中的算法(2)-支持向量机(SVM)基础&lt;/a&gt;)。&lt;/p&gt;
&lt;p&gt;除了SVM之外还有许多其它分类算法，例如Logistic回归(就是把线性回归掰弯)、神经网络等，尤其是人工神经网络(ANN)算法，由于其神经网络的隐喻与心理学之间“暧昧”的关系，确实也有见过认知心理学研究甚至直接拿训练神经网络作为认知模型，但在场景识别的研究中却很少见。SVM与神经网络都是基于线性模型发展出来的，但两派的纷争却一直不断，SVM算法的出现凭借着对小样本量的支持、易于实现、计算复杂度较小等优点一度占尽了风头，在认知心理学研究中的广泛应用从某种程度上来说也佐证了其众多优点。不过最近深度学习(Deep learning, 多层神经网络)算法的快速走红，不知道会不会给场景识别研究也带来新的春天？&lt;/p&gt;
&lt;p&gt;然而毕竟心理学研究不是为了追逐新潮的算法，我们更加关注的是人类行为背后的认知加工机制，大家采用同样的机器学习算法可能也是为了彼此研究之间的横向对比，因此在计算机视觉中更加注重的是算法的效能，包括准确率、健壮性、欠拟合过度拟合等问题，而在心理学研究中应用机器学习算法更加关注的是其分类结果中的错误模式(Error Pattern)，并将其与人类观察者的行为结果进行对比，从而验证关于&lt;strong&gt;特征选取&lt;/strong&gt;的假设，而算法的优劣则更像是一种系统偏差。&lt;/p&gt;
&lt;p&gt;当然除了SVM算法之外，场景识别研究也有很多心理学与计算机视觉交叉的研究方法与结果，包括很多JoV与CVPR等刊出的研究结果很有参考价值，下面列出几个非常重要的关于场景识别的计算模型，同样也是非常经典的认知模型(按发表时间顺序)，后续将会逐一介绍：&lt;/p&gt;
&lt;h4&gt;1. Spatial Envelope&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Oliva&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;Torralba&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2001&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt; &lt;span class="n"&gt;Modeling&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;shape&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;scene&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;holistic&lt;/span&gt; &lt;span class="n"&gt;representation&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;spatial&lt;/span&gt; &lt;span class="n"&gt;envelope&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;2. Bayesian Hierarchical Model&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Fei&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;Fei&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;.,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;Perona&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;P&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2005&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="n"&gt;bayesian&lt;/span&gt; &lt;span class="n"&gt;hierarchical&lt;/span&gt; &lt;span class="n"&gt;model&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;learning&lt;/span&gt; &lt;span class="n"&gt;natural&lt;/span&gt; &lt;span class="n"&gt;scene&lt;/span&gt; &lt;span class="n"&gt;categories&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;3. Contextual Guidance Model&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Torralba&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.,&lt;/span&gt; &lt;span class="n"&gt;Oliva&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;A&lt;/span&gt;&lt;span class="p"&gt;.,&lt;/span&gt; &lt;span class="n"&gt;Castelhano&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;S&lt;/span&gt;&lt;span class="p"&gt;.,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;Henderson&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;J&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;M&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2006&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt; &lt;span class="n"&gt;Contextual&lt;/span&gt; &lt;span class="n"&gt;guidance&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;eye&lt;/span&gt; &lt;span class="n"&gt;movements&lt;/span&gt; &lt;span class="n"&gt;and&lt;/span&gt; &lt;span class="n"&gt;attention&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;real&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;world&lt;/span&gt; &lt;span class="n"&gt;scenes&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;role&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;global&lt;/span&gt; &lt;span class="n"&gt;features&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;object&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;4. Bag of Visual Word(LDA系列的主题模型，选取最近一篇fMRI研究)&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;Stansbury&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;D&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;E&lt;/span&gt;&lt;span class="p"&gt;.,&lt;/span&gt; &lt;span class="n"&gt;Naselaris&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;T&lt;/span&gt;&lt;span class="p"&gt;.,&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;Gallant&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;J&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="n"&gt;L&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;2013&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt; &lt;span class="n"&gt;Natural&lt;/span&gt; &lt;span class="n"&gt;Scene&lt;/span&gt; &lt;span class="n"&gt;Statistics&lt;/span&gt; &lt;span class="n"&gt;Accountfor&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;Representation&lt;/span&gt; &lt;span class="n"&gt;of&lt;/span&gt; &lt;span class="n"&gt;Scene&lt;/span&gt; &lt;span class="n"&gt;Categories&lt;/span&gt; &lt;span class="n"&gt;in&lt;/span&gt; &lt;span class="n"&gt;Human&lt;/span&gt; &lt;span class="n"&gt;Visual&lt;/span&gt; &lt;span class="n"&gt;Cortex&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="Psychology"></category><category term="SVM"></category><category term="场景识别"></category><category term="Vision"></category></entry></feed>